<!doctype html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="../../static/css/atom.min.css">
    <!--
      Hi source code lover!!

      I don't want to be a YouTuber.
      I want to make a platform where people can share and learn college knowledge one another.
      If you are interested it, please get in touch with me. (Twitter: @cabernet_rock)
    -->

    <!-- SEO -->
    <title>10 minutes PRML Chapter 8</title>
    <meta name="description" content="Learn Pattern Recognition and Machine Learning in 10 minutes.">

    <!-- URL CANONICAL -->
    <!-- <link rel="canonical" href="http://your-url.com/permalink"> -->

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,700,700i%7CMaitree:200,300,400,600,700&amp;subset=latin-ext" rel="stylesheet">

    <!-- CSS Base -->
    <link rel="stylesheet" type='text/css' media='all' href="prml_static/css/webslides.css">

    <!-- Optional - CSS SVG Icons (Font Awesome) -->
    <link rel="stylesheet" type="text/css" media="all" href="prml_static/css/svg-icons.css">

    <!-- SOCIAL CARDS (Open Graph protocol) -->
    <!-- FACEBOOK -->
    <meta property="og:url" content="https://iwasakishuto.github.io">
    <meta property="og:type" content="article">
    <meta property="og:title" content="10 minutes PRML Chapter 8">
    <meta property="og:description" content="Learn Pattern Recognition and Machine Learning in 10 minutes.">
    <meta property="og:image" content="prml_static/images/share-webslides.jpg" >

    <!-- TWITTER -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@cabernet_rock">
    <meta name="twitter:title" content="10 minutes PRML Chapter 8">
    <meta name="twitter:description" content="Learn Pattern Recognition and Machine Learning in 10 minutes.">
    <meta name="twitter:image" content="prml_static/images/share-webslides.jpg">

    <!-- FAVICONS -->
    <link rel="shortcut icon" sizes="16x16" href="prml_static/images/favicons/favicon.png">
    <link rel="shortcut icon" sizes="32x32" href="prml_static/images/favicons/favicon-32.png">
    <link rel="apple-touch-icon icon" sizes="76x76" href="prml_static/images/favicons/favicon-76.png">
    <link rel="apple-touch-icon icon" sizes="120x120" href="prml_static/images/favicons/favicon-120.png">
    <link rel="apple-touch-icon icon" sizes="152x152" href="prml_static/images/favicons/favicon-152.png">
    <link rel="apple-touch-icon icon" sizes="180x180" href="prml_static/images/favicons/favicon-180.png">
    <link rel="apple-touch-icon icon" sizes="192x192" href="prml_static/images/favicons/favicon-192.png">

    <!-- Android -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#333333">

    <!-- Syntax highlight -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <!-- Tex -->
    <!-- Local env -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- Github env -->
    <!--
    <script type="text/javascript" async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
        }
      });
    </script>
  </head>

  <body>
    <header role="banner">
      <nav role="navigation">
        <ul>
          <li class="github">
            <a rel="external" href="#" title="YouTube">
              <svg class="fa-youtube">
                <use xlink:href="#fa-youtube"></use>
              </svg>
              <em>Colledge Knowledge</em>
            </a>
          </li>
          <li class="twitter">
            <a rel="external" href="https://twitter.com/cabernet_rock" title="Twitter">
              <svg class="fa-twitter">
                <use xlink:href="#fa-twitter"></use>
              </svg>
              <em>@cabernet_rock</em>
            </a>
          </li>
        </ul>
      </nav>
    </header>

    <main role="main">
      <article id="webslides">

        <!-- Quick Guide
          - Each parent <section> in the <article id="webslides"> element is an individual slide.
          - Vertical sliding = <article id="webslides" class="vertical">
          - <div class="wrap"> = container 90% / <div class="wrap size-50"> = 45%;
        -->

        <section class="bg-apple">
          <h1>§8 Graphical Models</h1>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>ベイジアンネットワーク</h2>
                <p class="text-intro">Bayesian network</p>
                <p><font color="red"><b>グラフィカルモデル(graphical model)</b></font>とは、有向グラフや無向グラフを用いて確率分布を表現したものである。グラフによって確率分布を表現することにはいくつかの利点がありますが、主に</p>
                <ol>
                  <li>確率モデルの構造を視覚化する簡単な方法を提供し、新しいモデルの設計方針を決めるのに役立つ。</li>
                  <li>グラフの構造を調べることにより、条件付き独立性などのモデルの性質に関する知見が得られる。</li>
                  <li>精巧なモデルにおいて推論や学習を実行するためには複雑な計算が必要になるが、これを数学的な表現を暗に伴うグラフ上の操作として表現することができる。</li>
                </ol>
                <p>といった利点があります。</p>
              </div>
              <div class="column">
                <p>グラフはリンク（辺）とノード（頂点）の集まりからなり、確率的グラフィカルモデルでは、</p>
                <ul class="description">
                  <li>
                    <span class="text-label">リンク：</span>
                    変数間の確率的関係を表現する。
                  </li>
                  <li>
                    <span class="text-label">ノード：</span>
                    確率変数を表現する。
                  </li>
                </ul>
                <p>となっています。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>実例</h2>
                <p class="text-intro">sample</p>
                <p>それでは、グラフ構造によって計算量がどれだけ抑えられるのかを見ていきます。</p>
                <p>例えば、離散的な確率変数 $A,B,C$ からなる確率分布を考えます。</p>
                <p>ここで、 $p(A,B,C)$ を $A,B$ に関して周辺化して $p(C)$ を求めたい場合、$p(C) = \sum_{A,B}p(A,B,C)$ という計算を行います。</p>
              </div>
              <div class="column">
                <p>これは、$p(C=c_k) = \sum_{i=1}^{N_A}\sum_{j=1}^{N_B}p(A=a_i,B=b_j,C=c_k)$ の略記ですが、$p(C)$ を求めるためには $k=1,2,\ldots,N_C$ それぞれに関して計算する必要があるので、$\mathcal{O}(N_AN_BN_C)$ の計算量が必要となります。</p>
                <p>続いて、分布 $p(A,B,C)$ に何らかの<font color="red"><b>条件付き独立性(conditional independence)</b></font>が存在する場合を考えます。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>条件付き独立性</h2>
                <p class="text-intro">conditional independence</p>
                <p>確率変数 $X,Y,C$ に対して、$p(Y|X,C) = p(Y|C)$ が成り立つ時、<font color="red"><b>「$C$ を所与として $X,Y$ は独立である」</b></font>と言います。なお、これは$p(X,Y|C) = p(X|C)p(Y|C)$ が成り立つことと同値です。</p>
              </div>
              <div class="column">
                <p>ここで、例えば $p(C|A,B) = p(C|B)$、つまり $B$ が与えられている条件下では、$A$ の条件は役に立たないということが成り立っている場合を考えます。</p>
                <p>すると、
                $$\begin{aligned}
                p(A,B,C) & = p(C|A,B)p(B|A)p(A)\\
                & = p(C|B)p(B|A)p(A)
                \end{aligned}$$となります。この状況を、以下の有向グラフで表現することができます。これを、この分布のベイジアンネットワークと言います。</p>
                <figure>
                  <img src="prml_static/images/Chap8/serial connection.png" alt="serial connection">
                </figure>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>条件付き独立性</h2>
                <p class="text-intro">conditional independence</p>
                <p>それでは、条件付き独立性を利用してどのようにデータ量・計算量を減らせるのかについて見てみます。</p>
                <p>$B$ を所与として $A,C$ が独立の場合、$p(A,B,C) = p(C|B)p(B|A)p(A)$ であるから、これを表現するためには $P(A),P(B|A),p(C|B)$ のそれぞれを表すことができれば十分です。</p>
                <p>したがって、テーブルサイズの和は $N_A + N_AN_B + N_BN_C$ となります。</p>
              </div>
              <div class="column">
                <p>また、$p(C)$ の計算を考えて見ます。すると、「$p(C|B)$ は $A$ に依存しない」ため、
                $$p(C) = \sum_{B}p(C|B)\sum_{A}p(B|A)p(A)$$とくくり出すことができます。</p>
                <p>これの計算コストは、$\mathcal{O}(N_AN_B + N_BN_C)$ となります。</p>
                <p>これより、もともと $\mathcal{O}(N_AN_BN_C)$ だった計算コストが大幅に減っていることがわかります。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>エビデンス</h2>
                <p class="text-intro">evidence</p>
                <p>ノード $C$ の値が $c$ であると既に分かっている場合の $p(A|C=c)$ を考えてみます。</p>
                <p>ここで、$C$ のように、その値が観測された確率変数に対応するノードを<font color="red"><b>エビデンスノード(evidence node)</b></font>と呼びます。</p>
                <p>また、この時<font color="red"><b>「$C$ はインスタンス化されている(instantiated)」</b></font>と言います。この概念は、ベイジアンネットワークを考える際に重要となります。</p>
              </div>
              <div class="column">
                <p>また、この時逆確率は、ベイズの定理を用いることで計算でき、
                $$p(A|C=c) = \frac{p(A,C=c)}{p(C=c)}$$となります。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>ベイジアンネットワーク</h2>
                <p class="text-intro">Bayesian network</p>
                <p>確率変数 $\mathbf{X} = (X_1,X_2,\ldots,X_N)$ からなるベイジアンネットワークは、以下により定まります。</p>
                <li>$\mathbf{X}$ をノード集合とする非循環有向グラフ(directed acyclic graph, DAG)</li>
                <li>各変数 $X_i$ に対する条件付き確率 $p\left(X_i|\mathrm{pa}(X_i)\right)$</li>
                <p>ただし、$\mathrm{pa}$ はノード $X_i$ の親ノードの集合を表します。</p>
              </div>
              <div class="column">
                <p class="text-intro">有向分離($D$ 分離)</p>
                <p>ベイジアンネットワークの中には、確率変数間の条件付き独立性が埋め込まれていますが、これを説明するのが<font color="red"><b>有向分離(D分離, d-separation)</b></font>という性質です。この時、
                $$\text{グラフ上でd分離}\rightarrow\text{分布上で独立}$$となるようにグラフを作ります。まずはじめに、ノードを３つだけ持つ簡単な３種類のグラフの例について考えます。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>有向分離($D$分離)</h2>
                <p class="text-intro">逐次結合 (serial connection, head-to-tail)</p>
                <figure>
                  <img src="prml_static/images/Chap8/serial connection.png" alt="serial connection" >
                </figure>
              </div>
              <div class="column">
                <p>逐次結合に関しては、<font color="red"><b>「$B$を所与として $A,C$ は $D$ 分離である」</b></font>と呼びます。</p>
                <p>この時、ノード $B$ は、ノード $A$ からノード $C$ への経路に関して<font color="red"><b> head-to-tail </b></font>であると言われます。</p>
              </div>
            </div>
          </div>
        </section>


        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>有向分離($D$分離)</h2>
                <p class="text-intro">分岐結合 (diverging connection, tail-to-tail) </p>
                <figure>
                  <img src="prml_static/images/Chap8/diverging connection.png" alt="diverging connection" width = "60%">
                </figure>
              </div>
              <div class="column">
                <p>分岐結合に関しては、<font color="red"><b>「$A$を所与として $B_1,B_2,\ldots,B_m$ は $D$ 分離である」</b></font>と呼びます。</p>
                <p>これは、例えば $A$ が「性別」$B,C$ が「背の高さ」と「髪の長さ」だとすると、
                $$\text{背が高い}\rightarrow\text{きっと男性だろう}\rightarrow\text{おそらく髪が短いだろう}$$という予測ができてしまいますが、性別がインスタンス化されているなら、背の高さと髪の長さに関係はなさそうです。</p>
                <p>この時、ノード $C$ は、この経路に関して<font color="red"><b> tail-to-tail </b></font>であると言われます。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>有向分離($D$分離)</h2>
                <p class="text-intro">合流結合 (converging connection) </p>
                <figure>
                  <img src="prml_static/images/Chap8/converging connection.png" alt="converging connection" width = "60%">
                </figure>
              </div>
              <div class="column">
                <p>合流結合に関しては、<font color="red"><b>「$A$ もしくは $A$ の子孫が所与でない（インスタンス化されていない）時、$B_1,B_2,\ldots,B_m$ は $D$ 分離である」</b></font>と言います。</p>
                <p>これは、例えば $C$ が「異常動作」であり、$A,B$ が「故障」、「バグ」であった場合、通常「バグ」と「故障」は独立です。</p>
                <p>しかし、「異常動作」がインスタンス化された時、
                $$\text{マシンが故障していないならバグがあるはず}$$という推論ができることになります。したがって、「異常動作」がインスタンス化されている時に「バグ」と「故障」が従属となります。</p>
                <p>この時、ノード $C$ は、この経路に関して<font color="red"><b> head-to-head </b></font>であると言われます。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>有向分離($D$分離)</h2>
                <p class="text-intro">まとめ(summary)</p>
                <p>ノード集合 $E$ が所与である（インスタンス化されている）時、ノード $X,Y$ を結ぶ（辺の向きを無視した）全てのパス上に、以下の条件を満たすノードが存在する時、<font color="red"><b>「$X,Y$ は $E$ を所与として $D$ 分離である」</b></font>と言います。</p>
                <li>逐次結合(head-to-tail)・分岐結合部(tail-to-tail)のノードであって、$E$ に含まれるもの</li>
                <li>合流結合部(head-to-head)のノードもしくはその子孫であって $E$ に含まれないもの</li>
              </div>
              <div class="column">
                <p>ここまでは一つ一つのノードの関係性を考えていましたが、ノード集合 $\mathbf{X,Y,C}$ に対する $D$ 分離性も同様に定義されます。</p>
                <p>つまり、$\mathbf{X}$ と $\mathbf{Y}$ 内の全てのノードのペアが $\mathbf{C}$ を所与として $D$ 分離になる時に、$\mathbf{X,Y}$ は $D$ 分離であると言います。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>インデペンデントマップ</h2>
                <p class="text-intro">independent map, I-map</p>
                <p>あるベイジアンネットワークのグラフ構造が
                $$ \text{グラフ上でD分離} \Rightarrow \text{確率分布上で条件付き独立} $$
                を全ての $\mathbf{X},\mathbf{Y},\mathbf{C}$ の組合せに対して満たす時、このグラフを<font color="red"><b>インデペンデントマップ(independent map, I-map)</b></font>と呼びます。</p>
                <p>$$ \text{確率分布上で条件付き独立} \Rightarrow \text{グラフ上でD分離}$$は一般に成り立たないので、I-mapとは確率分布の条件付き独立性の構造の一部を表現したものになります。</p>
                <p>また、これによって、グラフを分布とみなすことができる。</p>
              </div>
              <div class="column">
                <p class="text-intro">ベイジアンネットワークの表現する分布</p>
                <p>ベイジアンネットワークのグラフが I-map であるとき、
                $$p(\mathbf{X}) = \prod_i p(X_i|\mathrm{pa}(X_i))$$が成立します。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>ベイジアンネットワークでの推論</h2>
                <p class="text-intro">クエリ</p>
                <p>確率を求めたい変数の集合のことを<font color="red"><b> $Q$ (クエリ)</b></font>と言います。ベイジアンネットワークにおいて、$Q$  (クエリ)に対して同時確率 $p(Q)$ を計算することがベイジアンネットワークにおける基本的な推論の形式です。</p>
                <p>なお、条件付き確率も
                  $$p(\mathbf{X}|\mathbf{Y}) = \frac{p(\mathbf{X,Y})}{p(\mathbf{Y})}$$によって同時確率の計算に帰着することができるので、これを用いることで期待値の計算ができます。</p>
              </div>
              <div class="column">
                <p>
                  <ul>
                    <li>エビデンスが全くない状態での $p(Q)$ を<font color="red"><b>周辺事前分布 (marginal prior distribution)</b></font>と言います。</li>
                    <li>エビデンス $E$ が与えられた状態での $p(Q|E)$ を<font color="red"><b>周辺事後分布 (marginal posterior distribution) </b></font>と言います。</li>
                  </ul>
                </p>
                <p>それでは、実際にこれらの分布を求めていきます。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>周辺事前分布</h2>
                <p class="text-intro">marginal prior distribution</p>
                <p>それでは、以下のグラフが得られたとし、周辺事前分布 $p(B,E)$ を計算することを考えます。</p>
                <figure>
                  <img src="prml_static/images/Chap8/marginal prior distribution.png" width="50%" alt="marginal prior distribution">
                </figure>
                <p>$$p(A,B,C,D,E) = p(A)p(B)p(C|A,B)p(D|B)p(E|C,D)$$</p>
              </div>
              <div class="column">
                <p>ここで、$B,E$ 以外のノードに関して周辺化することで、
                $$p(B,E) = \sum_{A,C,D}p(A)p(B)p(C|A,B)p(D|B)p(E|C,D)$$という計算によって求めることができます。</p>
                <p>この計算を、条件付き独立の考え方を用いて整理（ $\sum$ に関して分配）すると、例えば
                $$ p(B,E) = p(B)\sum_{D}p(D|B)\sum_{C}p(E|C,D)\sum_{A}p(A)p(C|A,B)$$となります。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>周辺事前分布</h2>
                <p class="text-intro">marginal prior distribution</p>
                <figure>
                  <img src="prml_static/images/Chap8/marginal prior distribution.png" width="50%" alt="marginal prior distribution">
                </figure>
                <p>計算の流れを具体的に書き下すと、次のようになります。</p>
                <p>なお、この途中計算に現れた因数、つまり $\mathcal{S}$ の要素を<font color="red"><b>ファクター（factor）</b></font>と呼びます。この時ファクターの集合から1文字ずつ変数が消えていくので、このアルゴリズムを<font color="red"><b>変数消去アルゴリズム(variable elimination)</b></font>と呼びます。</p>
                <p>右に、$p(B,E)$ を求める方法を具体的に示します。</p>
              </div>
              <div class="column">
                <p>$$\mathcal{S} = \{p(A),p(B),p(C|A,B),p(D|B),p(E|C,D)\}$$</p>
                <ol>
                  <li>$A$を含むもの全てを掛けあわせて足して、それらを $\mathcal{S}$ から除く。
                      計算した $ \varphi(B,C) = \sum_{A}p(A)p(C|A,B) $ を追加して、$$\mathcal{S} = \{p(B),p(D|B),p(E|C,D),\varphi(B,C)\}$$</li>
                  <li>$C$ を含むもの全てを掛けあわせて足して、それらを $\mathcal{S}$ から除く。
                      計算した $ \varphi(B,D,E) = \sum_{C}p(E|C,D)\varphi(B,C) $ を追加して$$\mathcal{S} = \{p(B),p(D|B),\varphi(B,D,E)\}$$</li>
                  <li>$D$ を含むもの全てを掛けあわせて足して、それらを $\mathcal{S}$ から除く。
                      計算した $ \varphi(B,E) = \sum_{D}p(D|B)\varphi(B,D,E) $ を追加して$$\mathcal{S} = \{p(B),\varphi(B,E)\}$$</li>
                  <li>最後に残った $\mathcal{S}$ の要素を全て掛けたものを出力する。
                      $$ p(B,E) = p(B)\varphi(B,E) $$</li>
                </ol>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>ベイジアンネットワーク上での推論</h2>
                <p class="text-intro">グラフ理論的な考察</p>
                <p>ここまで考えてきたのは確率密度関数の因数分解であり、
                $$ p(\mathbf{X}) = \prod_i p(X_i|\mathrm{pa}(X_i)) $$を計算してきました。</p>
                <p>このアルゴリズムはネットワークのグラフ構造を一切考慮していません。そこで、せっかくグラフ構造を作成したので、グラフ理論的な考察によって計算量を削減することを目指します。</p>
              </div>
              <div class="column">
                <p>ここでは、<font color="red"><b>枝刈り(pruning)</b></font>という概念を紹介します。枝刈りは、推論に無関係のノードを消去することで計算量を減らす方法です。</p>
                <p>例えば以下の図で、$\mathbf{Q}=\{D\},\mathbf{E}=\{A\}$ である場合、ノード $E$ は $D$ に関する推論とは全く無関係です。</p>
                <figure>
                  <img src="prml_static/images/Chap8/bayesian network.png" width="50%" alt="bayesian network">
                </figure>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>枝刈り</h2>
                <p class="text-intro">pruning</p>
                <figure>
                  <img src="prml_static/images/Chap8/bayesian network.png" width="50%" alt="bayesian network">
                </figure>
                <p>$\mathbf{Q}=\{D\},\mathbf{E}=\{A\}$ である時にノード $E$ が $D$ に関する推論とは全く無関係であり、除去できる根拠を数学的に説明すると、
                $$ \begin{aligned}p(A,D)&=\sum_{B,C,E}p(E|C)p(D|B,C)p(C|A)p(B|A)p(A) \\&=\sum_{B,C}p(D|B,C)p(C|A)p(B|A)p(A)\sum_EP(E|C)\end{aligned} $$において、$\sum_EP(E|C) = 1$ であるからです。</p>
              </div>
              <div class="column">
                <p>ちなみにこの場合、さらにエビデンスノード $A$ を除去することもでき、例えば $A$ の観測値が $a$ であるならば、
                $$\begin{aligned}p(A=a,D) &=\sum_{B,C}p(D|B,C)p(C|A= a)p(B|A= a)p(A= a) \\\end{aligned}$$
                であり、$p(A=a)=1$ となることで証明ができます。</p>
                <p class="text-intro">summary</p>
                <p>クエリ集合 $\mathbf{Q}$ とエビデンス集合 $\mathbf{E}$ が与えられた時、</p>
                <li>$\mathbf{Q}$ に含まれない葉ノード(子を持たないノード)へ向かうエッジ</li>
                <li>$\mathbf{E}$ に含まれるノードから張られたエッジ</li>
                <p>を除去することができます。また、枝刈りを実行した結果除去できるようになるノードができる可能性もあるので、収束するまで実行する必要があります。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>変数消去法の計算量</h2>
                <p>変数消去法の計算量には、変数の数 $N$ はもちろん、<font color="red"><b>変数を消去する順番</b></font>も大きく関係します。</p>
                <p>例えば、$p(A,B,C) = p(C|B)p(B|A)p(A)$ から $A,B$ を消去する場合、消去順に寄って以下のような違いが出ます。</p>
                <p class="text-intro">$A\rightarrow B$ の順に消去した場合</p>
                <ol>
                  <li>$\varphi(B) = \sum_{A}p(B|A)p(A)$ を計算</li>
                  <li>$p(C) = \sum_{B}p(C|B)\varphi(B)$ を計算</li>
                </ol>
                <hr>
                <p class="text-intro">$B\rightarrow A$ の順に消去した場合</p>
                <ol>
                  <li>$\varphi(A,C) = \sum_{B}p(C|B)p(B|A)$ を計算</li>
                  <li>$p(C) = \sum_A\varphi(A,C)p(A)$ を計算</li>
                </ol>
              </div>
              <div class="column">
                <p>この時、 $B\rightarrow A$ の順に消去した場合は、$\varphi(A,C)$ という因子が残り、計算量が増えてしまいました。</p>
                <p>一般に、変数消去法の計算量について、次のことが言えます。</p>
                <p>変数の数を $N$、変数消去の途中に出現する因子の変数の数の最大値を $w (width)$ とすると、変数消去法の計算量は <b>$ \mathcal{O}(N^2\mathrm{exp}(w))$</b> となります。</p>
                <p>このことから、$w$ が最小となるような変数消去順序を求めれば良いのですが、この問題は<font color="red"><b>NP困難</b></font>であることがわかっています。</p>
                <p>そこで、ヒューリスティックによる<font color="red"><b>最小次数法 (minimum degree method) </b></font>を紹介します。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>インタラクショングラフ</h2>
                <p class="text-intro">Interaction graph</p>
                <p>ファクターの集合 $\mathcal{S}=\{\varphi_1,\ldots,\varphi_n\}$ に対するインタラクショングラフ $\mathcal{G}_i$ とは無向グラフであり、頂点集合 $\mathbf{V}$ と辺集合 $\mathbf{E}$ は以下のように定めます。
                  $$\begin{aligned}\mathbf{V} &= \{\varphi_1,\ldots\varphi_n\text{に含まれる各変数}\}\\
                  \mathbf{E} &= \{(x,y) \,|\, \text{$x,y$ が同一のファクターに含まれる}\} \end{aligned}$$</p>
                <p>例）再び $p(A,B,C,D,E) = p(A)p(B)p(C|A,B)p(D|B)p(E|C,D)$ を例に考えてみます。</p>
                <figure>
                  <img src="prml_static/images/Chap8/marginal prior distribution.png" width="50%" alt="marginal prior distribution">
                </figure>
              </div>
              <div class="column">
                <p>この時、最初の $\mathbf{S}$ の状態は
                $$\mathcal{S} = \{p(A),p(B),p(C|A,B),p(D|B),p(E|C,D)\}$$となり、対応するインタラクショングラフは下図のようになります。</p>
                <figure>
                  <img src="prml_static/images/Chap8/interaction graph.png" width="50%" alt="interaction graph">
                </figure>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>インタラクショングラフ</h2>
                <p class="text-intro">Interaction graph</p>
                <p>次に、ここから $B$ を消去します。すると、
                $$ \varphi(A,C,D)= \sum_Bp(B)p(C|A,B)p(D|B)$$
                となり、
                $$ \mathcal{S}' = \{p(A),\varphi(A,C,D),p(E|C,D)\}$$となります。この時これに対応するインタラクショングラフは右のようになります。</p>
                <p>この推移は、<font color="red"><b>「削除したノードに隣接していたノード同士を新たに繋ぎ直す」</b></font>ことで行うことができ、<font color="red"><b>「$X$ を消去して出来る因子の変数の数」= 「$X$ の $\mathcal{G}_i$ での次数」</b></font>であることがわかります。</p>
              </div>
              <div class="column">
                <figure>
                  <img src="prml_static/images/Chap8/interaction graph2.png" width="50%" alt="interaction graph2">
                </figure>
                <p>したがって、<font color="red"><b>「常にインタラクショングラフ上で次数が最小の変数を消去する」</b></font>というヒューリスティックス的な手法を考えます。これが、<font color="red"><b>最小次数法</b></font>です。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2>ファクター消去法</h2>
                <p class="text-intro">factor elimination</p>
                <p>最小字数法ではそれほど計算量のオーダーは変わりません。そこで、<font color="red"><b>ジョインツリーアルゴリズム(join tree algorithm)</b></font>という $\mathcal{O}(N\times\mathrm{exp}(w))$ の計算量で厳密な推論を行う事ができるアルゴリズムを考えます。</p>
                <p>ジョインツリーアルゴリズムはを理解するために、まずはファクター消去法という、以下の手順で推論を行う方法を紹介します。</p>
                <ol>
                  <li>クエリ $\mathbf{Q}$ を全て持つファクターを考える。なければ、テーブルを掛け合わせて作成する。</li>
                  <li>基本的には、上のファクター以外のテーブルを他のテーブルに掛け合わせる</li>
                  <li>プライベート変数（そのノードしか持っていない変数）なら、たたみ込む（周辺化）</li>
                </ol>
              </div>
              <div class="column">
                <p>変数消去方との違いを考えると、
                  <li>変数消去法では、$D$ 以外の変数を１つずつ消す事によってこれを計算する。</li>
                  <li>ファクター消去法では、$D$ を含む適当な1つのファクター（例えば $p(D|B)$ ）以外のファクターを1つずつ消す事によってこれを計算する。</li>
                </p>
                <p>ということになります。<font color="red"><b>「ファクター $\varphi$ の変数 $\mathbf{Q}$ 以外を足しあわせて消去する」</b></font>という操作は良く使うので、
                $$ \mathrm{proj}(\varphi, \mathbf{Q}) \stackrel{\mathrm{def}}{\Longleftrightarrow} \sum_{\mathrm{vars}\varphi-\mathbf{Q}}\varphi $$
                と書くことにします。ただし、 $\mathrm{vars}\varphi$ は $\varphi$ に含まれる変数の集合を表します。</p>
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple">
          <div class="wrap">
            <div class="grid vertical-align">
              <div class="column">
                <h2></h2>
                <p class="text-intro"></p>
              </div>
              <div class="column">
              </div>
            </div>
          </div>
        </section>

        <section class="bg-apple aligncenter">
          <h2 class="text-emoji zoomIn">😊</h2>
          <h3><strong>Thank you!</strong></h2>
          <p><a href="https://twitter.com/cabernet_rock" title="@cabernet_rock on Twitter">@cabernet_rock</a></p>
        </section>

        <section class="bg-apple aligncenter">
          <!-- .wrap = container (width: 90%) -->
          <div class="wrap">
            <h2><strong>Please see my YouTube </strong></h2>
            <p class="text-intro">I'm explaining this slide.</p>
            <p>
              <a href="#" class="button" title="See YouTube">
                <svg class="fa-youtube">
                  <use xlink:href="#fa-youtube"></use>
                </svg>
                See my YouTube
              </a>
            </p>
          </div>
        </section>

      </article>
    </main>
    <!--main-->

    <!-- Required -->
    <script src="prml_static/js/webslides.js"></script>

    <script>
      window.ws = new WebSlides();
    </script>

    <!-- OPTIONAL - svg-icons.js (fontastic.me - Font Awesome as svg icons) -->
    <script defer src="prml_static/js/svg-icons.js"></script>

  </body>
</html>
